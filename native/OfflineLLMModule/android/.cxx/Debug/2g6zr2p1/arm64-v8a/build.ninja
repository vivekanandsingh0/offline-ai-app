# CMAKE generated file: DO NOT EDIT!
# Generated by "Ninja" Generator, CMake Version 3.22

# This file contains all the build statements describing the
# compilation DAG.

# =============================================================================
# Write statements declared in CMakeLists.txt:
# 
# Which is the root file.
# =============================================================================

# =============================================================================
# Project: offlinellm
# Configurations: Debug
# =============================================================================

#############################################
# Minimal version of Ninja required by this file

ninja_required_version = 1.5


#############################################
# Set configuration variable for custom commands.

CONFIGURATION = Debug
# =============================================================================
# Include auxiliary files.


#############################################
# Include rules file.

include CMakeFiles/rules.ninja

# =============================================================================

#############################################
# Logical path to working directory; prefix for absolute paths.

cmake_ninja_workdir = C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/.cxx/Debug/2g6zr2p1/arm64-v8a/
# =============================================================================
# Object build statements for SHARED_LIBRARY target offlinellm


#############################################
# Order-only phony target for offlinellm

build cmake_object_order_depends_target_offlinellm: phony || cmake_object_order_depends_target_ggml cmake_object_order_depends_target_ggml-base cmake_object_order_depends_target_ggml-cpu cmake_object_order_depends_target_llama

build CMakeFiles/offlinellm.dir/cpp/bridge.cpp.o: CXX_COMPILER__offlinellm_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/bridge.cpp || cmake_object_order_depends_target_offlinellm
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_SHARED -Dofflinellm_EXPORTS
  DEP_FILE = CMakeFiles\offlinellm.dir\cpp\bridge.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/common" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = CMakeFiles\offlinellm.dir
  OBJECT_FILE_DIR = CMakeFiles\offlinellm.dir\cpp
  TARGET_COMPILE_PDB = CMakeFiles\offlinellm.dir\
  TARGET_PDB = ..\..\..\..\build\intermediates\cxx\Debug\2g6zr2p1\obj\arm64-v8a\libofflinellm.pdb


# =============================================================================
# Link build statements for SHARED_LIBRARY target offlinellm


#############################################
# Link the shared library ..\..\..\..\build\intermediates\cxx\Debug\2g6zr2p1\obj\arm64-v8a\libofflinellm.so

build ../../../../build/intermediates/cxx/Debug/2g6zr2p1/obj/arm64-v8a/libofflinellm.so: CXX_SHARED_LIBRARY_LINKER__offlinellm_Debug CMakeFiles/offlinellm.dir/cpp/bridge.cpp.o | bin/libllama.so bin/libggml.so bin/libggml-cpu.so bin/libggml-base.so || bin/libggml-base.so bin/libggml-cpu.so bin/libggml.so bin/libllama.so
  LANGUAGE_COMPILE_FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info
  LINK_FLAGS = -Wl,--build-id=sha1 -Wl,--no-rosegment -Wl,--no-undefined-version -Wl,--fatal-warnings -Wl,--no-undefined -Qunused-arguments
  LINK_LIBRARIES = bin/libllama.so  -llog  -landroid  bin/libggml.so  bin/libggml-cpu.so  bin/libggml-base.so  -latomic -lm
  OBJECT_DIR = CMakeFiles\offlinellm.dir
  POST_BUILD = cd .
  PRE_LINK = cd .
  SONAME = libofflinellm.so
  SONAME_FLAG = -Wl,-soname,
  TARGET_COMPILE_PDB = CMakeFiles\offlinellm.dir\
  TARGET_FILE = ..\..\..\..\build\intermediates\cxx\Debug\2g6zr2p1\obj\arm64-v8a\libofflinellm.so
  TARGET_PDB = ..\..\..\..\build\intermediates\cxx\Debug\2g6zr2p1\obj\arm64-v8a\libofflinellm.pdb


#############################################
# Utility command for edit_cache

build CMakeFiles/edit_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe -E echo "No interactive CMake dialog available.""
  DESC = No interactive CMake dialog available...
  restat = 1

build edit_cache: phony CMakeFiles/edit_cache.util


#############################################
# Utility command for rebuild_cache

build CMakeFiles/rebuild_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe --regenerate-during-build -S"C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android" -B"C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a""
  DESC = Running CMake to regenerate build system...
  pool = console
  restat = 1

build rebuild_cache: phony CMakeFiles/rebuild_cache.util


#############################################
# Utility command for list_install_components

build list_install_components: phony


#############################################
# Utility command for install

build CMakeFiles/install.util: CUSTOM_COMMAND all
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe -P cmake_install.cmake"
  DESC = Install the project...
  pool = console
  restat = 1

build install: phony CMakeFiles/install.util


#############################################
# Utility command for install/local

build CMakeFiles/install/local.util: CUSTOM_COMMAND all
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe -DCMAKE_INSTALL_LOCAL_ONLY=1 -P cmake_install.cmake"
  DESC = Installing only the local directory...
  pool = console
  restat = 1

build install/local: phony CMakeFiles/install/local.util


#############################################
# Utility command for install/strip

build CMakeFiles/install/strip.util: CUSTOM_COMMAND all
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe -DCMAKE_INSTALL_DO_STRIP=1 -P cmake_install.cmake"
  DESC = Installing the project stripped...
  pool = console
  restat = 1

build install/strip: phony CMakeFiles/install/strip.util

# =============================================================================
# Write statements declared in CMakeLists.txt:
# C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/CMakeLists.txt
# =============================================================================


#############################################
# Utility command for edit_cache

build cpp/llama.cpp/CMakeFiles/edit_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a\cpp\llama.cpp" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe -E echo "No interactive CMake dialog available.""
  DESC = No interactive CMake dialog available...
  restat = 1

build cpp/llama.cpp/edit_cache: phony cpp/llama.cpp/CMakeFiles/edit_cache.util


#############################################
# Utility command for rebuild_cache

build cpp/llama.cpp/CMakeFiles/rebuild_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a\cpp\llama.cpp" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe --regenerate-during-build -S"C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android" -B"C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a""
  DESC = Running CMake to regenerate build system...
  pool = console
  restat = 1

build cpp/llama.cpp/rebuild_cache: phony cpp/llama.cpp/CMakeFiles/rebuild_cache.util


#############################################
# Utility command for list_install_components

build cpp/llama.cpp/list_install_components: phony


#############################################
# Utility command for install

build cpp/llama.cpp/CMakeFiles/install.util: CUSTOM_COMMAND cpp/llama.cpp/all
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a\cpp\llama.cpp" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe -P cmake_install.cmake"
  DESC = Install the project...
  pool = console
  restat = 1

build cpp/llama.cpp/install: phony cpp/llama.cpp/CMakeFiles/install.util


#############################################
# Utility command for install/local

build cpp/llama.cpp/CMakeFiles/install/local.util: CUSTOM_COMMAND cpp/llama.cpp/all
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a\cpp\llama.cpp" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe -DCMAKE_INSTALL_LOCAL_ONLY=1 -P cmake_install.cmake"
  DESC = Installing only the local directory...
  pool = console
  restat = 1

build cpp/llama.cpp/install/local: phony cpp/llama.cpp/CMakeFiles/install/local.util


#############################################
# Utility command for install/strip

build cpp/llama.cpp/CMakeFiles/install/strip.util: CUSTOM_COMMAND cpp/llama.cpp/all
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a\cpp\llama.cpp" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe -DCMAKE_INSTALL_DO_STRIP=1 -P cmake_install.cmake"
  DESC = Installing the project stripped...
  pool = console
  restat = 1

build cpp/llama.cpp/install/strip: phony cpp/llama.cpp/CMakeFiles/install/strip.util

# =============================================================================
# Write statements declared in CMakeLists.txt:
# C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/CMakeLists.txt
# =============================================================================


#############################################
# Utility command for edit_cache

build cpp/llama.cpp/ggml/CMakeFiles/edit_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a\cpp\llama.cpp\ggml" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe -E echo "No interactive CMake dialog available.""
  DESC = No interactive CMake dialog available...
  restat = 1

build cpp/llama.cpp/ggml/edit_cache: phony cpp/llama.cpp/ggml/CMakeFiles/edit_cache.util


#############################################
# Utility command for rebuild_cache

build cpp/llama.cpp/ggml/CMakeFiles/rebuild_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a\cpp\llama.cpp\ggml" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe --regenerate-during-build -S"C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android" -B"C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a""
  DESC = Running CMake to regenerate build system...
  pool = console
  restat = 1

build cpp/llama.cpp/ggml/rebuild_cache: phony cpp/llama.cpp/ggml/CMakeFiles/rebuild_cache.util


#############################################
# Utility command for list_install_components

build cpp/llama.cpp/ggml/list_install_components: phony


#############################################
# Utility command for install

build cpp/llama.cpp/ggml/CMakeFiles/install.util: CUSTOM_COMMAND cpp/llama.cpp/ggml/all
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a\cpp\llama.cpp\ggml" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe -P cmake_install.cmake"
  DESC = Install the project...
  pool = console
  restat = 1

build cpp/llama.cpp/ggml/install: phony cpp/llama.cpp/ggml/CMakeFiles/install.util


#############################################
# Utility command for install/local

build cpp/llama.cpp/ggml/CMakeFiles/install/local.util: CUSTOM_COMMAND cpp/llama.cpp/ggml/all
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a\cpp\llama.cpp\ggml" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe -DCMAKE_INSTALL_LOCAL_ONLY=1 -P cmake_install.cmake"
  DESC = Installing only the local directory...
  pool = console
  restat = 1

build cpp/llama.cpp/ggml/install/local: phony cpp/llama.cpp/ggml/CMakeFiles/install/local.util


#############################################
# Utility command for install/strip

build cpp/llama.cpp/ggml/CMakeFiles/install/strip.util: CUSTOM_COMMAND cpp/llama.cpp/ggml/all
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a\cpp\llama.cpp\ggml" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe -DCMAKE_INSTALL_DO_STRIP=1 -P cmake_install.cmake"
  DESC = Installing the project stripped...
  pool = console
  restat = 1

build cpp/llama.cpp/ggml/install/strip: phony cpp/llama.cpp/ggml/CMakeFiles/install/strip.util

# =============================================================================
# Write statements declared in CMakeLists.txt:
# C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/CMakeLists.txt
# =============================================================================

# =============================================================================
# Object build statements for SHARED_LIBRARY target ggml-base


#############################################
# Order-only phony target for ggml-base

build cmake_object_order_depends_target_ggml-base: phony || cpp/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir

build cpp/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o: C_COMPILER__ggml-base_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml.c || cmake_object_order_depends_target_ggml-base
  DEFINES = -DGGML_BUILD -DGGML_COMMIT=\"54189c0\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.9.4\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS
  DEP_FILE = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir\ggml.c.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -fno-limit-debug-info  -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wdouble-promotion -pthread -std=gnu11
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir\
  TARGET_PDB = bin\libggml-base.pdb

build cpp/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml.cpp.o: CXX_COMPILER__ggml-base_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml.cpp || cmake_object_order_depends_target_ggml-base
  DEFINES = -DGGML_BUILD -DGGML_COMMIT=\"54189c0\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.9.4\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS
  DEP_FILE = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir\ggml.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -pthread -std=gnu++17
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir\
  TARGET_PDB = bin\libggml-base.pdb

build cpp/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o: C_COMPILER__ggml-base_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-alloc.c || cmake_object_order_depends_target_ggml-base
  DEFINES = -DGGML_BUILD -DGGML_COMMIT=\"54189c0\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.9.4\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS
  DEP_FILE = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir\ggml-alloc.c.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -fno-limit-debug-info  -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wdouble-promotion -pthread -std=gnu11
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir\
  TARGET_PDB = bin\libggml-base.pdb

build cpp/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o: CXX_COMPILER__ggml-base_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-backend.cpp || cmake_object_order_depends_target_ggml-base
  DEFINES = -DGGML_BUILD -DGGML_COMMIT=\"54189c0\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.9.4\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS
  DEP_FILE = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir\ggml-backend.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -pthread -std=gnu++17
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir\
  TARGET_PDB = bin\libggml-base.pdb

build cpp/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o: CXX_COMPILER__ggml-base_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-opt.cpp || cmake_object_order_depends_target_ggml-base
  DEFINES = -DGGML_BUILD -DGGML_COMMIT=\"54189c0\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.9.4\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS
  DEP_FILE = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir\ggml-opt.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -pthread -std=gnu++17
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir\
  TARGET_PDB = bin\libggml-base.pdb

build cpp/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o: CXX_COMPILER__ggml-base_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-threading.cpp || cmake_object_order_depends_target_ggml-base
  DEFINES = -DGGML_BUILD -DGGML_COMMIT=\"54189c0\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.9.4\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS
  DEP_FILE = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir\ggml-threading.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -pthread -std=gnu++17
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir\
  TARGET_PDB = bin\libggml-base.pdb

build cpp/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o: C_COMPILER__ggml-base_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-quants.c || cmake_object_order_depends_target_ggml-base
  DEFINES = -DGGML_BUILD -DGGML_COMMIT=\"54189c0\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.9.4\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS
  DEP_FILE = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir\ggml-quants.c.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -fno-limit-debug-info  -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wdouble-promotion -pthread -std=gnu11
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir\
  TARGET_PDB = bin\libggml-base.pdb

build cpp/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o: CXX_COMPILER__ggml-base_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/gguf.cpp || cmake_object_order_depends_target_ggml-base
  DEFINES = -DGGML_BUILD -DGGML_COMMIT=\"54189c0\" -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_VERSION=\"0.9.4\" -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_base_EXPORTS
  DEP_FILE = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir\gguf.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -pthread -std=gnu++17
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir\
  TARGET_PDB = bin\libggml-base.pdb


# =============================================================================
# Link build statements for SHARED_LIBRARY target ggml-base


#############################################
# Link the shared library bin\libggml-base.so

build bin/libggml-base.so: CXX_SHARED_LIBRARY_LINKER__ggml-base_Debug cpp/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o cpp/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml.cpp.o cpp/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o cpp/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o cpp/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o cpp/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o cpp/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o cpp/llama.cpp/ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o
  LANGUAGE_COMPILE_FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info
  LINK_FLAGS = -Wl,--build-id=sha1 -Wl,--no-rosegment -Wl,--no-undefined-version -Wl,--fatal-warnings -Wl,--no-undefined -Qunused-arguments
  LINK_LIBRARIES = -lm  -ldl  -pthread  -latomic -lm
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir
  POST_BUILD = cd .
  PRE_LINK = cd .
  SONAME = libggml-base.so
  SONAME_FLAG = -Wl,-soname,
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-base.dir\
  TARGET_FILE = bin\libggml-base.so
  TARGET_PDB = bin\libggml-base.pdb

# =============================================================================
# Object build statements for SHARED_LIBRARY target ggml


#############################################
# Order-only phony target for ggml

build cmake_object_order_depends_target_ggml: phony || cmake_object_order_depends_target_ggml-base cmake_object_order_depends_target_ggml-cpu

build cpp/llama.cpp/ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o: CXX_COMPILER__ggml_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-backend-reg.cpp || cmake_object_order_depends_target_ggml
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_BUILD -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS
  DEP_FILE = cpp\llama.cpp\ggml\src\CMakeFiles\ggml.dir\ggml-backend-reg.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -std=gnu++17
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml.dir\
  TARGET_PDB = bin\libggml.pdb


# =============================================================================
# Link build statements for SHARED_LIBRARY target ggml


#############################################
# Link the shared library bin\libggml.so

build bin/libggml.so: CXX_SHARED_LIBRARY_LINKER__ggml_Debug cpp/llama.cpp/ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o | bin/libggml-cpu.so bin/libggml-base.so || bin/libggml-base.so bin/libggml-cpu.so
  LANGUAGE_COMPILE_FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info
  LINK_FLAGS = -Wl,--build-id=sha1 -Wl,--no-rosegment -Wl,--no-undefined-version -Wl,--fatal-warnings -Wl,--no-undefined -Qunused-arguments
  LINK_LIBRARIES = bin/libggml-cpu.so  bin/libggml-base.so  -latomic -lm
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml.dir
  POST_BUILD = cd .
  PRE_LINK = cd .
  SONAME = libggml.so
  SONAME_FLAG = -Wl,-soname,
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml.dir\
  TARGET_FILE = bin\libggml.so
  TARGET_PDB = bin\libggml.pdb

# =============================================================================
# Object build statements for SHARED_LIBRARY target ggml-cpu


#############################################
# Order-only phony target for ggml-cpu

build cmake_object_order_depends_target_ggml-cpu: phony || cmake_object_order_depends_target_ggml-base

build cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o: C_COMPILER__ggml-cpu_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu/ggml-cpu.c || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\ggml-cpu.c.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -fno-limit-debug-info  -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wdouble-promotion -fopenmp=libomp -std=gnu11
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/.." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\
  TARGET_PDB = bin\libggml-cpu.pdb

build cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o: CXX_COMPILER__ggml-cpu_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu/ggml-cpu.cpp || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\ggml-cpu.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -fopenmp=libomp -std=gnu++17
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/.." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\
  TARGET_PDB = bin\libggml-cpu.pdb

build cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/repack.cpp.o: CXX_COMPILER__ggml-cpu_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu/repack.cpp || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\repack.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -fopenmp=libomp -std=gnu++17
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/.." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\
  TARGET_PDB = bin\libggml-cpu.pdb

build cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/hbm.cpp.o: CXX_COMPILER__ggml-cpu_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu/hbm.cpp || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\hbm.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -fopenmp=libomp -std=gnu++17
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/.." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\
  TARGET_PDB = bin\libggml-cpu.pdb

build cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/quants.c.o: C_COMPILER__ggml-cpu_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu/quants.c || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\quants.c.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -fno-limit-debug-info  -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wdouble-promotion -fopenmp=libomp -std=gnu11
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/.." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\
  TARGET_PDB = bin\libggml-cpu.pdb

build cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/traits.cpp.o: CXX_COMPILER__ggml-cpu_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu/traits.cpp || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\traits.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -fopenmp=libomp -std=gnu++17
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/.." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\
  TARGET_PDB = bin\libggml-cpu.pdb

build cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o: CXX_COMPILER__ggml-cpu_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu/amx/amx.cpp || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\amx\amx.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -fopenmp=libomp -std=gnu++17
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/.." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\amx
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\
  TARGET_PDB = bin\libggml-cpu.pdb

build cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o: CXX_COMPILER__ggml-cpu_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu/amx/mmq.cpp || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\amx\mmq.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -fopenmp=libomp -std=gnu++17
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/.." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\amx
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\
  TARGET_PDB = bin\libggml-cpu.pdb

build cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o: CXX_COMPILER__ggml-cpu_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu/binary-ops.cpp || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\binary-ops.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -fopenmp=libomp -std=gnu++17
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/.." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\
  TARGET_PDB = bin\libggml-cpu.pdb

build cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o: CXX_COMPILER__ggml-cpu_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu/unary-ops.cpp || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\unary-ops.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -fopenmp=libomp -std=gnu++17
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/.." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\
  TARGET_PDB = bin\libggml-cpu.pdb

build cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o: CXX_COMPILER__ggml-cpu_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu/vec.cpp || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\vec.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -fopenmp=libomp -std=gnu++17
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/.." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\
  TARGET_PDB = bin\libggml-cpu.pdb

build cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o: CXX_COMPILER__ggml-cpu_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu/ops.cpp || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\ops.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -fopenmp=libomp -std=gnu++17
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/.." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\
  TARGET_PDB = bin\libggml-cpu.pdb

build cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o: CXX_COMPILER__ggml-cpu_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu/llamafile/sgemm.cpp || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\llamafile\sgemm.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -fopenmp=libomp -std=gnu++17
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/.." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\llamafile
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\
  TARGET_PDB = bin\libggml-cpu.pdb

build cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/arm/quants.c.o: C_COMPILER__ggml-cpu_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu/arch/arm/quants.c || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\arch\arm\quants.c.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -fno-limit-debug-info  -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wdouble-promotion -fopenmp=libomp -std=gnu11
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/.." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\arch\arm
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\
  TARGET_PDB = bin\libggml-cpu.pdb

build cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/arm/repack.cpp.o: CXX_COMPILER__ggml-cpu_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu/arch/arm/repack.cpp || cmake_object_order_depends_target_ggml-cpu
  DEFINES = -DGGML_BACKEND_BUILD -DGGML_BACKEND_SHARED -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CPU_REPACK -DGGML_USE_LLAMAFILE -DGGML_USE_OPENMP -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_cpu_EXPORTS
  DEP_FILE = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\arch\arm\repack.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi -fopenmp=libomp -std=gnu++17
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/.." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/ggml-cpu" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\ggml-cpu\arch\arm
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\
  TARGET_PDB = bin\libggml-cpu.pdb


# =============================================================================
# Link build statements for SHARED_LIBRARY target ggml-cpu


#############################################
# Link the shared library bin\libggml-cpu.so

build bin/libggml-cpu.so: CXX_SHARED_LIBRARY_LINKER__ggml-cpu_Debug cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/repack.cpp.o cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/hbm.cpp.o cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/quants.c.o cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/traits.cpp.o cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/llamafile/sgemm.cpp.o cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/arm/quants.c.o cpp/llama.cpp/ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/arm/repack.cpp.o | bin/libggml-base.so C$:/Users/birba/AppData/Local/Android/Sdk/ndk/27.0.12077973/toolchains/llvm/prebuilt/windows-x86_64/lib/clang/18/lib/linux/aarch64/libomp.so || bin/libggml-base.so
  LANGUAGE_COMPILE_FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info
  LINK_FLAGS = -Wl,--build-id=sha1 -Wl,--no-rosegment -Wl,--no-undefined-version -Wl,--fatal-warnings -Wl,--no-undefined -Qunused-arguments
  LINK_LIBRARIES = bin/libggml-base.so  C:/Users/birba/AppData/Local/Android/Sdk/ndk/27.0.12077973/toolchains/llvm/prebuilt/windows-x86_64/lib/clang/18/lib/linux/aarch64/libomp.so  -latomic -lm
  OBJECT_DIR = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir
  POST_BUILD = cd .
  PRE_LINK = cd .
  SONAME = libggml-cpu.so
  SONAME_FLAG = -Wl,-soname,
  TARGET_COMPILE_PDB = cpp\llama.cpp\ggml\src\CMakeFiles\ggml-cpu.dir\
  TARGET_FILE = bin\libggml-cpu.so
  TARGET_PDB = bin\libggml-cpu.pdb


#############################################
# Utility command for edit_cache

build cpp/llama.cpp/ggml/src/CMakeFiles/edit_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a\cpp\llama.cpp\ggml\src" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe -E echo "No interactive CMake dialog available.""
  DESC = No interactive CMake dialog available...
  restat = 1

build cpp/llama.cpp/ggml/src/edit_cache: phony cpp/llama.cpp/ggml/src/CMakeFiles/edit_cache.util


#############################################
# Utility command for rebuild_cache

build cpp/llama.cpp/ggml/src/CMakeFiles/rebuild_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a\cpp\llama.cpp\ggml\src" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe --regenerate-during-build -S"C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android" -B"C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a""
  DESC = Running CMake to regenerate build system...
  pool = console
  restat = 1

build cpp/llama.cpp/ggml/src/rebuild_cache: phony cpp/llama.cpp/ggml/src/CMakeFiles/rebuild_cache.util


#############################################
# Utility command for list_install_components

build cpp/llama.cpp/ggml/src/list_install_components: phony


#############################################
# Utility command for install

build cpp/llama.cpp/ggml/src/CMakeFiles/install.util: CUSTOM_COMMAND cpp/llama.cpp/ggml/src/all
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a\cpp\llama.cpp\ggml\src" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe -P cmake_install.cmake"
  DESC = Install the project...
  pool = console
  restat = 1

build cpp/llama.cpp/ggml/src/install: phony cpp/llama.cpp/ggml/src/CMakeFiles/install.util


#############################################
# Utility command for install/local

build cpp/llama.cpp/ggml/src/CMakeFiles/install/local.util: CUSTOM_COMMAND cpp/llama.cpp/ggml/src/all
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a\cpp\llama.cpp\ggml\src" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe -DCMAKE_INSTALL_LOCAL_ONLY=1 -P cmake_install.cmake"
  DESC = Installing only the local directory...
  pool = console
  restat = 1

build cpp/llama.cpp/ggml/src/install/local: phony cpp/llama.cpp/ggml/src/CMakeFiles/install/local.util


#############################################
# Utility command for install/strip

build cpp/llama.cpp/ggml/src/CMakeFiles/install/strip.util: CUSTOM_COMMAND cpp/llama.cpp/ggml/src/all
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a\cpp\llama.cpp\ggml\src" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe -DCMAKE_INSTALL_DO_STRIP=1 -P cmake_install.cmake"
  DESC = Installing the project stripped...
  pool = console
  restat = 1

build cpp/llama.cpp/ggml/src/install/strip: phony cpp/llama.cpp/ggml/src/CMakeFiles/install/strip.util

# =============================================================================
# Write statements declared in CMakeLists.txt:
# C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/CMakeLists.txt
# =============================================================================


#############################################
# Utility command for edit_cache

build cpp/llama.cpp/ggml/src/ggml-cpu/CMakeFiles/edit_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a\cpp\llama.cpp\ggml\src\ggml-cpu" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe -E echo "No interactive CMake dialog available.""
  DESC = No interactive CMake dialog available...
  restat = 1

build cpp/llama.cpp/ggml/src/ggml-cpu/edit_cache: phony cpp/llama.cpp/ggml/src/ggml-cpu/CMakeFiles/edit_cache.util


#############################################
# Utility command for rebuild_cache

build cpp/llama.cpp/ggml/src/ggml-cpu/CMakeFiles/rebuild_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a\cpp\llama.cpp\ggml\src\ggml-cpu" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe --regenerate-during-build -S"C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android" -B"C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a""
  DESC = Running CMake to regenerate build system...
  pool = console
  restat = 1

build cpp/llama.cpp/ggml/src/ggml-cpu/rebuild_cache: phony cpp/llama.cpp/ggml/src/ggml-cpu/CMakeFiles/rebuild_cache.util


#############################################
# Utility command for list_install_components

build cpp/llama.cpp/ggml/src/ggml-cpu/list_install_components: phony


#############################################
# Utility command for install

build cpp/llama.cpp/ggml/src/ggml-cpu/CMakeFiles/install.util: CUSTOM_COMMAND cpp/llama.cpp/ggml/src/ggml-cpu/all
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a\cpp\llama.cpp\ggml\src\ggml-cpu" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe -P cmake_install.cmake"
  DESC = Install the project...
  pool = console
  restat = 1

build cpp/llama.cpp/ggml/src/ggml-cpu/install: phony cpp/llama.cpp/ggml/src/ggml-cpu/CMakeFiles/install.util


#############################################
# Utility command for install/local

build cpp/llama.cpp/ggml/src/ggml-cpu/CMakeFiles/install/local.util: CUSTOM_COMMAND cpp/llama.cpp/ggml/src/ggml-cpu/all
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a\cpp\llama.cpp\ggml\src\ggml-cpu" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe -DCMAKE_INSTALL_LOCAL_ONLY=1 -P cmake_install.cmake"
  DESC = Installing only the local directory...
  pool = console
  restat = 1

build cpp/llama.cpp/ggml/src/ggml-cpu/install/local: phony cpp/llama.cpp/ggml/src/ggml-cpu/CMakeFiles/install/local.util


#############################################
# Utility command for install/strip

build cpp/llama.cpp/ggml/src/ggml-cpu/CMakeFiles/install/strip.util: CUSTOM_COMMAND cpp/llama.cpp/ggml/src/ggml-cpu/all
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a\cpp\llama.cpp\ggml\src\ggml-cpu" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe -DCMAKE_INSTALL_DO_STRIP=1 -P cmake_install.cmake"
  DESC = Installing the project stripped...
  pool = console
  restat = 1

build cpp/llama.cpp/ggml/src/ggml-cpu/install/strip: phony cpp/llama.cpp/ggml/src/ggml-cpu/CMakeFiles/install/strip.util

# =============================================================================
# Write statements declared in CMakeLists.txt:
# C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/CMakeLists.txt
# =============================================================================

# =============================================================================
# Object build statements for SHARED_LIBRARY target llama


#############################################
# Order-only phony target for llama

build cmake_object_order_depends_target_llama: phony || cmake_object_order_depends_target_ggml cmake_object_order_depends_target_ggml-base cmake_object_order_depends_target_ggml-cpu

build cpp/llama.cpp/src/CMakeFiles/llama.dir/llama.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/llama.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\llama.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-adapter.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/llama-adapter.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\llama-adapter.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-arch.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/llama-arch.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\llama-arch.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-batch.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/llama-batch.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\llama-batch.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-chat.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/llama-chat.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\llama-chat.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-context.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/llama-context.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\llama-context.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-cparams.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/llama-cparams.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\llama-cparams.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-grammar.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/llama-grammar.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\llama-grammar.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-graph.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/llama-graph.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\llama-graph.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-hparams.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/llama-hparams.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\llama-hparams.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-impl.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/llama-impl.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\llama-impl.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-io.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/llama-io.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\llama-io.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-kv-cache.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/llama-kv-cache.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\llama-kv-cache.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-kv-cache-iswa.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/llama-kv-cache-iswa.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\llama-kv-cache-iswa.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-memory.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/llama-memory.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\llama-memory.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-memory-hybrid.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/llama-memory-hybrid.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\llama-memory-hybrid.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-memory-recurrent.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/llama-memory-recurrent.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\llama-memory-recurrent.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-mmap.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/llama-mmap.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\llama-mmap.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-model-loader.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/llama-model-loader.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\llama-model-loader.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-model-saver.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/llama-model-saver.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\llama-model-saver.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-model.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/llama-model.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\llama-model.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-quant.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/llama-quant.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\llama-quant.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-sampling.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/llama-sampling.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\llama-sampling.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-vocab.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/llama-vocab.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\llama-vocab.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/unicode-data.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/unicode-data.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\unicode-data.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/unicode.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/unicode.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\unicode.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/afmoe.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/afmoe.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\afmoe.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/apertus.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/apertus.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\apertus.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/arcee.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/arcee.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\arcee.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/arctic.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/arctic.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\arctic.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/arwkv7.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/arwkv7.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\arwkv7.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/baichuan.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/baichuan.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\baichuan.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/bailingmoe.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/bailingmoe.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\bailingmoe.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/bailingmoe2.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/bailingmoe2.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\bailingmoe2.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/bert.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/bert.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\bert.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/bitnet.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/bitnet.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\bitnet.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/bloom.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/bloom.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\bloom.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/chameleon.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/chameleon.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\chameleon.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/chatglm.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/chatglm.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\chatglm.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/codeshell.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/codeshell.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\codeshell.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/cogvlm.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/cogvlm.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\cogvlm.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/cohere2-iswa.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/cohere2-iswa.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\cohere2-iswa.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/command-r.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/command-r.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\command-r.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/dbrx.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/dbrx.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\dbrx.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/deci.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/deci.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\deci.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/deepseek.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/deepseek.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\deepseek.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/deepseek2.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/deepseek2.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\deepseek2.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/dots1.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/dots1.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\dots1.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/dream.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/dream.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\dream.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/ernie4-5-moe.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/ernie4-5-moe.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\ernie4-5-moe.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/ernie4-5.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/ernie4-5.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\ernie4-5.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/exaone.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/exaone.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\exaone.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/exaone4.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/exaone4.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\exaone4.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/falcon-h1.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/falcon-h1.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\falcon-h1.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/falcon.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/falcon.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\falcon.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/gemma-embedding.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/gemma-embedding.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\gemma-embedding.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/gemma.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/gemma.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\gemma.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/gemma2-iswa.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/gemma2-iswa.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\gemma2-iswa.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/gemma3.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/gemma3.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\gemma3.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/gemma3n-iswa.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/gemma3n-iswa.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\gemma3n-iswa.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/glm4-moe.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/glm4-moe.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\glm4-moe.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/glm4.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/glm4.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\glm4.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/gpt2.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/gpt2.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\gpt2.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/gptneox.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/gptneox.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\gptneox.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/granite-hybrid.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/granite-hybrid.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\granite-hybrid.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/granite.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/granite.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\granite.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/grok.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/grok.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\grok.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/grovemoe.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/grovemoe.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\grovemoe.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/hunyuan-dense.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/hunyuan-dense.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\hunyuan-dense.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/hunyuan-moe.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/hunyuan-moe.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\hunyuan-moe.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/internlm2.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/internlm2.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\internlm2.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/jais.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/jais.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\jais.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/jamba.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/jamba.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\jamba.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/lfm2.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/lfm2.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\lfm2.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/llada-moe.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/llada-moe.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\llada-moe.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/llada.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/llada.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\llada.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/llama-iswa.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/llama-iswa.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\llama-iswa.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/llama.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/llama.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\llama.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/mamba.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/mamba.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\mamba.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/minicpm3.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/minicpm3.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\minicpm3.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/minimax-m2.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/minimax-m2.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\minimax-m2.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/mpt.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/mpt.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\mpt.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/nemotron-h.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/nemotron-h.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\nemotron-h.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/nemotron.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/nemotron.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\nemotron.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/neo-bert.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/neo-bert.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\neo-bert.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/olmo.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/olmo.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\olmo.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/olmo2.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/olmo2.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\olmo2.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/olmoe.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/olmoe.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\olmoe.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/openai-moe-iswa.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/openai-moe-iswa.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\openai-moe-iswa.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/openelm.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/openelm.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\openelm.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/orion.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/orion.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\orion.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/pangu-embedded.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/pangu-embedded.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\pangu-embedded.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/phi2.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/phi2.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\phi2.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/phi3.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/phi3.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\phi3.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/plamo.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/plamo.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\plamo.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/plamo2.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/plamo2.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\plamo2.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/plm.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/plm.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\plm.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/qwen.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/qwen.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\qwen.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/qwen2.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/qwen2.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\qwen2.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/qwen2moe.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/qwen2moe.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\qwen2moe.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/qwen2vl.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/qwen2vl.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\qwen2vl.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/qwen3.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/qwen3.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\qwen3.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/qwen3vl.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/qwen3vl.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\qwen3vl.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/qwen3vl-moe.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/qwen3vl-moe.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\qwen3vl-moe.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/qwen3moe.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/qwen3moe.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\qwen3moe.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/qwen3next.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/qwen3next.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\qwen3next.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/refact.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/refact.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\refact.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/rnd1.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/rnd1.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\rnd1.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/rwkv6-base.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/rwkv6-base.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\rwkv6-base.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/rwkv6.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/rwkv6.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\rwkv6.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/rwkv6qwen2.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/rwkv6qwen2.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\rwkv6qwen2.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/rwkv7-base.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/rwkv7-base.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\rwkv7-base.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/rwkv7.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/rwkv7.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\rwkv7.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/seed-oss.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/seed-oss.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\seed-oss.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/smallthinker.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/smallthinker.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\smallthinker.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/smollm3.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/smollm3.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\smollm3.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/stablelm.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/stablelm.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\stablelm.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/starcoder.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/starcoder.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\starcoder.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/starcoder2.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/starcoder2.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\starcoder2.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/t5-dec.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/t5-dec.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\t5-dec.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/t5-enc.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/t5-enc.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\t5-enc.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/wavtokenizer-dec.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/wavtokenizer-dec.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\wavtokenizer-dec.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/xverse.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/xverse.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\xverse.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/mistral3.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/mistral3.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\mistral3.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb

build cpp/llama.cpp/src/CMakeFiles/llama.dir/models/graph-context-mamba.cpp.o: CXX_COMPILER__llama_Debug C$:/Vivekanand$ folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/models/graph-context-mamba.cpp || cmake_object_order_depends_target_llama
  DEFINES = -DGGML_BACKEND_SHARED -DGGML_SHARED -DGGML_USE_CPU -DLLAMA_BUILD -DLLAMA_SHARED -Dllama_EXPORTS
  DEP_FILE = cpp\llama.cpp\src\CMakeFiles\llama.dir\models\graph-context-mamba.cpp.o.d
  FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info  -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wunreachable-code-break -Wunreachable-code-return -Wmissing-prototypes -Wextra-semi
  INCLUDES = -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/." -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/src/../include" -I"C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/cpp/llama.cpp/ggml/src/../include"
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  OBJECT_FILE_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir\models
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_PDB = bin\libllama.pdb


# =============================================================================
# Link build statements for SHARED_LIBRARY target llama


#############################################
# Link the shared library bin\libllama.so

build bin/libllama.so: CXX_SHARED_LIBRARY_LINKER__llama_Debug cpp/llama.cpp/src/CMakeFiles/llama.dir/llama.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-adapter.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-arch.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-batch.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-chat.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-context.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-cparams.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-grammar.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-graph.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-hparams.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-impl.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-io.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-kv-cache.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-kv-cache-iswa.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-memory.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-memory-hybrid.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-memory-recurrent.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-mmap.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-model-loader.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-model-saver.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-model.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-quant.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-sampling.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/llama-vocab.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/unicode-data.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/unicode.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/afmoe.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/apertus.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/arcee.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/arctic.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/arwkv7.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/baichuan.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/bailingmoe.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/bailingmoe2.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/bert.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/bitnet.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/bloom.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/chameleon.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/chatglm.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/codeshell.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/cogvlm.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/cohere2-iswa.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/command-r.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/dbrx.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/deci.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/deepseek.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/deepseek2.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/dots1.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/dream.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/ernie4-5-moe.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/ernie4-5.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/exaone.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/exaone4.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/falcon-h1.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/falcon.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/gemma-embedding.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/gemma.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/gemma2-iswa.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/gemma3.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/gemma3n-iswa.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/glm4-moe.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/glm4.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/gpt2.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/gptneox.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/granite-hybrid.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/granite.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/grok.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/grovemoe.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/hunyuan-dense.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/hunyuan-moe.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/internlm2.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/jais.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/jamba.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/lfm2.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/llada-moe.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/llada.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/llama-iswa.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/llama.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/mamba.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/minicpm3.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/minimax-m2.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/mpt.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/nemotron-h.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/nemotron.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/neo-bert.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/olmo.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/olmo2.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/olmoe.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/openai-moe-iswa.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/openelm.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/orion.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/pangu-embedded.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/phi2.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/phi3.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/plamo.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/plamo2.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/plm.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/qwen.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/qwen2.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/qwen2moe.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/qwen2vl.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/qwen3.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/qwen3vl.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/qwen3vl-moe.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/qwen3moe.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/qwen3next.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/refact.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/rnd1.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/rwkv6-base.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/rwkv6.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/rwkv6qwen2.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/rwkv7-base.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/rwkv7.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/seed-oss.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/smallthinker.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/smollm3.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/stablelm.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/starcoder.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/starcoder2.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/t5-dec.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/t5-enc.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/wavtokenizer-dec.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/xverse.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/mistral3.cpp.o cpp/llama.cpp/src/CMakeFiles/llama.dir/models/graph-context-mamba.cpp.o | bin/libggml.so bin/libggml-cpu.so bin/libggml-base.so || bin/libggml-base.so bin/libggml-cpu.so bin/libggml.so
  LANGUAGE_COMPILE_FLAGS = -g -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security  -std=c++17 -fno-limit-debug-info
  LINK_FLAGS = -Wl,--build-id=sha1 -Wl,--no-rosegment -Wl,--no-undefined-version -Wl,--fatal-warnings -Wl,--no-undefined -Qunused-arguments
  LINK_LIBRARIES = bin/libggml.so  bin/libggml-cpu.so  bin/libggml-base.so  -latomic -lm
  OBJECT_DIR = cpp\llama.cpp\src\CMakeFiles\llama.dir
  POST_BUILD = cd .
  PRE_LINK = cd .
  SONAME = libllama.so
  SONAME_FLAG = -Wl,-soname,
  TARGET_COMPILE_PDB = cpp\llama.cpp\src\CMakeFiles\llama.dir\
  TARGET_FILE = bin\libllama.so
  TARGET_PDB = bin\libllama.pdb
  RSP_FILE = CMakeFiles\llama.rsp


#############################################
# Utility command for edit_cache

build cpp/llama.cpp/src/CMakeFiles/edit_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a\cpp\llama.cpp\src" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe -E echo "No interactive CMake dialog available.""
  DESC = No interactive CMake dialog available...
  restat = 1

build cpp/llama.cpp/src/edit_cache: phony cpp/llama.cpp/src/CMakeFiles/edit_cache.util


#############################################
# Utility command for rebuild_cache

build cpp/llama.cpp/src/CMakeFiles/rebuild_cache.util: CUSTOM_COMMAND
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a\cpp\llama.cpp\src" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe --regenerate-during-build -S"C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android" -B"C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a""
  DESC = Running CMake to regenerate build system...
  pool = console
  restat = 1

build cpp/llama.cpp/src/rebuild_cache: phony cpp/llama.cpp/src/CMakeFiles/rebuild_cache.util


#############################################
# Utility command for list_install_components

build cpp/llama.cpp/src/list_install_components: phony


#############################################
# Utility command for install

build cpp/llama.cpp/src/CMakeFiles/install.util: CUSTOM_COMMAND cpp/llama.cpp/src/all
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a\cpp\llama.cpp\src" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe -P cmake_install.cmake"
  DESC = Install the project...
  pool = console
  restat = 1

build cpp/llama.cpp/src/install: phony cpp/llama.cpp/src/CMakeFiles/install.util


#############################################
# Utility command for install/local

build cpp/llama.cpp/src/CMakeFiles/install/local.util: CUSTOM_COMMAND cpp/llama.cpp/src/all
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a\cpp\llama.cpp\src" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe -DCMAKE_INSTALL_LOCAL_ONLY=1 -P cmake_install.cmake"
  DESC = Installing only the local directory...
  pool = console
  restat = 1

build cpp/llama.cpp/src/install/local: phony cpp/llama.cpp/src/CMakeFiles/install/local.util


#############################################
# Utility command for install/strip

build cpp/llama.cpp/src/CMakeFiles/install/strip.util: CUSTOM_COMMAND cpp/llama.cpp/src/all
  COMMAND = cmd.exe /C "cd /D "C:\Vivekanand folder\offline-ai-app\native\OfflineLLMModule\android\.cxx\Debug\2g6zr2p1\arm64-v8a\cpp\llama.cpp\src" && C:\Users\birba\AppData\Local\Android\Sdk\cmake\3.22.1\bin\cmake.exe -DCMAKE_INSTALL_DO_STRIP=1 -P cmake_install.cmake"
  DESC = Installing the project stripped...
  pool = console
  restat = 1

build cpp/llama.cpp/src/install/strip: phony cpp/llama.cpp/src/CMakeFiles/install/strip.util

# =============================================================================
# Target aliases.

build ggml: phony bin/libggml.so

build ggml-base: phony bin/libggml-base.so

build ggml-cpu: phony bin/libggml-cpu.so

build libggml-base.so: phony bin/libggml-base.so

build libggml-cpu.so: phony bin/libggml-cpu.so

build libggml.so: phony bin/libggml.so

build libllama.so: phony bin/libllama.so

build libofflinellm.so: phony ../../../../build/intermediates/cxx/Debug/2g6zr2p1/obj/arm64-v8a/libofflinellm.so

build llama: phony bin/libllama.so

build offlinellm: phony ../../../../build/intermediates/cxx/Debug/2g6zr2p1/obj/arm64-v8a/libofflinellm.so

# =============================================================================
# Folder targets.

# =============================================================================

#############################################
# Folder: C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/.cxx/Debug/2g6zr2p1/arm64-v8a

build all: phony ../../../../build/intermediates/cxx/Debug/2g6zr2p1/obj/arm64-v8a/libofflinellm.so cpp/llama.cpp/all

# =============================================================================

#############################################
# Folder: C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/.cxx/Debug/2g6zr2p1/arm64-v8a/cpp/llama.cpp

build cpp/llama.cpp/all: phony cpp/llama.cpp/ggml/all cpp/llama.cpp/src/all

# =============================================================================

#############################################
# Folder: C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/.cxx/Debug/2g6zr2p1/arm64-v8a/cpp/llama.cpp/ggml

build cpp/llama.cpp/ggml/all: phony cpp/llama.cpp/ggml/src/all

# =============================================================================

#############################################
# Folder: C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/.cxx/Debug/2g6zr2p1/arm64-v8a/cpp/llama.cpp/ggml/src

build cpp/llama.cpp/ggml/src/all: phony bin/libggml-base.so bin/libggml.so bin/libggml-cpu.so cpp/llama.cpp/ggml/src/ggml-cpu/all

# =============================================================================

#############################################
# Folder: C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/.cxx/Debug/2g6zr2p1/arm64-v8a/cpp/llama.cpp/ggml/src/ggml-cpu

build cpp/llama.cpp/ggml/src/ggml-cpu/all: phony

# =============================================================================

#############################################
# Folder: C:/Vivekanand folder/offline-ai-app/native/OfflineLLMModule/android/.cxx/Debug/2g6zr2p1/arm64-v8a/cpp/llama.cpp/src

build cpp/llama.cpp/src/all: phony bin/libllama.so

# =============================================================================
# Built-in targets


#############################################
# Re-run CMake if any of its inputs changed.

build build.ninja: RERUN_CMAKE | ../../../../CMakeLists.txt ../../../../cpp/llama.cpp/CMakeLists.txt ../../../../cpp/llama.cpp/cmake/build-info.cmake ../../../../cpp/llama.cpp/cmake/common.cmake ../../../../cpp/llama.cpp/cmake/llama-config.cmake.in ../../../../cpp/llama.cpp/cmake/llama.pc.in ../../../../cpp/llama.cpp/ggml/CMakeLists.txt ../../../../cpp/llama.cpp/ggml/cmake/common.cmake ../../../../cpp/llama.cpp/ggml/cmake/ggml-config.cmake.in ../../../../cpp/llama.cpp/ggml/src/CMakeLists.txt ../../../../cpp/llama.cpp/ggml/src/ggml-cpu/CMakeLists.txt ../../../../cpp/llama.cpp/src/CMakeLists.txt C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/BasicConfigVersion-SameMajorVersion.cmake.in C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeASMCompiler.cmake.in C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeASMInformation.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeCCompiler.cmake.in C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeCCompilerABI.c C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeCInformation.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeCXXCompiler.cmake.in C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeCXXCompilerABI.cpp C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeCXXInformation.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeCheckCompilerFlagCommonPatterns.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeCommonLanguageInclude.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeCompilerIdDetection.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeDetermineASMCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeDetermineCCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeDetermineCXXCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeDetermineCompileFeatures.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeDetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeDetermineCompilerABI.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeDetermineCompilerId.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeDetermineSystem.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeFindBinUtils.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeGenericSystem.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeInitializeConfigs.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeLanguageInformation.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakePackageConfigHelpers.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeParseImplicitIncludeInfo.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeParseImplicitLinkInfo.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeParseLibraryArchitecture.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeSystem.cmake.in C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeSystemSpecificInformation.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeSystemSpecificInitialize.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeTestASMCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeTestCCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeTestCXXCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeTestCompilerCommon.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckCSourceCompiles.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckCXXCompilerFlag.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckCXXSourceCompiles.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckForPthreads.c C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckIncludeFile.c.in C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckIncludeFile.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckIncludeFileCXX.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckLibraryExists.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/ADSP-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/ARMCC-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/ARMClang-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/AppleClang-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Borland-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Bruce-C-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/CMakeCommonCompilerMacros.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Clang-ASM.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Clang-C.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Clang-CXX.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Clang-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Clang-DetermineCompilerInternal.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Clang-FindBinUtils.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Clang.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Comeau-CXX-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Compaq-C-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Compaq-CXX-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Cray-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Embarcadero-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Fujitsu-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/FujitsuClang-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/GHS-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/GNU-C-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/GNU-CXX-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/GNU.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/HP-C-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/HP-CXX-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/IAR-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/IBMCPP-C-DetermineVersionInternal.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/IBMCPP-CXX-DetermineVersionInternal.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Intel-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/IntelLLVM-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/MSVC-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/NVHPC-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/NVIDIA-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/OpenWatcom-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/PGI-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/PathScale-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/SCO-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/SDCC-C-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/SunPro-C-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/SunPro-CXX-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/TI-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/TinyCC-C-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/VisualAge-C-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/VisualAge-CXX-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Watcom-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/XL-C-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/XL-CXX-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/XLClang-C-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/XLClang-CXX-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/zOS-C-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/zOS-CXX-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/FindGit.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/FindOpenMP.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/FindPackageHandleStandardArgs.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/FindPackageMessage.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/FindThreads.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/GNUInstallDirs.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Internal/CheckCompilerFlag.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Internal/CheckSourceCompiles.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Internal/FeatureTesting.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android-Clang-ASM.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android-Clang-C.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android-Clang-CXX.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android-Clang.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android-Determine-C.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android-Determine-CXX.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android-Determine.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android-Initialize.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android/Determine-Compiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Linux.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/UnixPaths.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/WriteBasicConfigVersionFile.cmake C$:/Users/birba/AppData/Local/Android/Sdk/ndk/27.0.12077973/build/cmake/abis.cmake C$:/Users/birba/AppData/Local/Android/Sdk/ndk/27.0.12077973/build/cmake/android-legacy.toolchain.cmake C$:/Users/birba/AppData/Local/Android/Sdk/ndk/27.0.12077973/build/cmake/android.toolchain.cmake C$:/Users/birba/AppData/Local/Android/Sdk/ndk/27.0.12077973/build/cmake/flags.cmake C$:/Users/birba/AppData/Local/Android/Sdk/ndk/27.0.12077973/build/cmake/hooks/pre/Android-Clang.cmake C$:/Users/birba/AppData/Local/Android/Sdk/ndk/27.0.12077973/build/cmake/hooks/pre/Android-Determine.cmake C$:/Users/birba/AppData/Local/Android/Sdk/ndk/27.0.12077973/build/cmake/hooks/pre/Android-Initialize.cmake C$:/Users/birba/AppData/Local/Android/Sdk/ndk/27.0.12077973/build/cmake/hooks/pre/Android.cmake C$:/Users/birba/AppData/Local/Android/Sdk/ndk/27.0.12077973/build/cmake/hooks/pre/Determine-Compiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/ndk/27.0.12077973/build/cmake/platforms.cmake CMakeCache.txt CMakeFiles/3.22.1-g37088a8-dirty/CMakeASMCompiler.cmake CMakeFiles/3.22.1-g37088a8-dirty/CMakeCCompiler.cmake CMakeFiles/3.22.1-g37088a8-dirty/CMakeCXXCompiler.cmake CMakeFiles/3.22.1-g37088a8-dirty/CMakeSystem.cmake CMakeFiles/FindOpenMP/OpenMPCheckVersion.c CMakeFiles/FindOpenMP/OpenMPCheckVersion.cpp CMakeFiles/FindOpenMP/OpenMPTryFlag.c CMakeFiles/FindOpenMP/OpenMPTryFlag.cpp
  pool = console


#############################################
# A missing CMake input file is not an error.

build ../../../../CMakeLists.txt ../../../../cpp/llama.cpp/CMakeLists.txt ../../../../cpp/llama.cpp/cmake/build-info.cmake ../../../../cpp/llama.cpp/cmake/common.cmake ../../../../cpp/llama.cpp/cmake/llama-config.cmake.in ../../../../cpp/llama.cpp/cmake/llama.pc.in ../../../../cpp/llama.cpp/ggml/CMakeLists.txt ../../../../cpp/llama.cpp/ggml/cmake/common.cmake ../../../../cpp/llama.cpp/ggml/cmake/ggml-config.cmake.in ../../../../cpp/llama.cpp/ggml/src/CMakeLists.txt ../../../../cpp/llama.cpp/ggml/src/ggml-cpu/CMakeLists.txt ../../../../cpp/llama.cpp/src/CMakeLists.txt C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/BasicConfigVersion-SameMajorVersion.cmake.in C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeASMCompiler.cmake.in C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeASMInformation.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeCCompiler.cmake.in C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeCCompilerABI.c C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeCInformation.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeCXXCompiler.cmake.in C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeCXXCompilerABI.cpp C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeCXXInformation.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeCheckCompilerFlagCommonPatterns.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeCommonLanguageInclude.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeCompilerIdDetection.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeDetermineASMCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeDetermineCCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeDetermineCXXCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeDetermineCompileFeatures.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeDetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeDetermineCompilerABI.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeDetermineCompilerId.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeDetermineSystem.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeFindBinUtils.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeGenericSystem.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeInitializeConfigs.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeLanguageInformation.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakePackageConfigHelpers.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeParseImplicitIncludeInfo.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeParseImplicitLinkInfo.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeParseLibraryArchitecture.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeSystem.cmake.in C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeSystemSpecificInformation.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeSystemSpecificInitialize.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeTestASMCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeTestCCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeTestCXXCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CMakeTestCompilerCommon.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckCSourceCompiles.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckCXXCompilerFlag.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckCXXSourceCompiles.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckForPthreads.c C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckIncludeFile.c.in C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckIncludeFile.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckIncludeFileCXX.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/CheckLibraryExists.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/ADSP-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/ARMCC-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/ARMClang-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/AppleClang-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Borland-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Bruce-C-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/CMakeCommonCompilerMacros.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Clang-ASM.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Clang-C.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Clang-CXX.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Clang-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Clang-DetermineCompilerInternal.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Clang-FindBinUtils.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Clang.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Comeau-CXX-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Compaq-C-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Compaq-CXX-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Cray-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Embarcadero-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Fujitsu-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/FujitsuClang-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/GHS-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/GNU-C-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/GNU-CXX-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/GNU.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/HP-C-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/HP-CXX-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/IAR-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/IBMCPP-C-DetermineVersionInternal.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/IBMCPP-CXX-DetermineVersionInternal.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Intel-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/IntelLLVM-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/MSVC-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/NVHPC-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/NVIDIA-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/OpenWatcom-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/PGI-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/PathScale-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/SCO-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/SDCC-C-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/SunPro-C-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/SunPro-CXX-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/TI-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/TinyCC-C-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/VisualAge-C-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/VisualAge-CXX-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/Watcom-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/XL-C-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/XL-CXX-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/XLClang-C-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/XLClang-CXX-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/zOS-C-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Compiler/zOS-CXX-DetermineCompiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/FindGit.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/FindOpenMP.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/FindPackageHandleStandardArgs.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/FindPackageMessage.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/FindThreads.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/GNUInstallDirs.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Internal/CheckCompilerFlag.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Internal/CheckSourceCompiles.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Internal/FeatureTesting.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android-Clang-ASM.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android-Clang-C.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android-Clang-CXX.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android-Clang.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android-Determine-C.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android-Determine-CXX.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android-Determine.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android-Initialize.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Android/Determine-Compiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/Linux.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/Platform/UnixPaths.cmake C$:/Users/birba/AppData/Local/Android/Sdk/cmake/3.22.1/share/cmake-3.22/Modules/WriteBasicConfigVersionFile.cmake C$:/Users/birba/AppData/Local/Android/Sdk/ndk/27.0.12077973/build/cmake/abis.cmake C$:/Users/birba/AppData/Local/Android/Sdk/ndk/27.0.12077973/build/cmake/android-legacy.toolchain.cmake C$:/Users/birba/AppData/Local/Android/Sdk/ndk/27.0.12077973/build/cmake/android.toolchain.cmake C$:/Users/birba/AppData/Local/Android/Sdk/ndk/27.0.12077973/build/cmake/flags.cmake C$:/Users/birba/AppData/Local/Android/Sdk/ndk/27.0.12077973/build/cmake/hooks/pre/Android-Clang.cmake C$:/Users/birba/AppData/Local/Android/Sdk/ndk/27.0.12077973/build/cmake/hooks/pre/Android-Determine.cmake C$:/Users/birba/AppData/Local/Android/Sdk/ndk/27.0.12077973/build/cmake/hooks/pre/Android-Initialize.cmake C$:/Users/birba/AppData/Local/Android/Sdk/ndk/27.0.12077973/build/cmake/hooks/pre/Android.cmake C$:/Users/birba/AppData/Local/Android/Sdk/ndk/27.0.12077973/build/cmake/hooks/pre/Determine-Compiler.cmake C$:/Users/birba/AppData/Local/Android/Sdk/ndk/27.0.12077973/build/cmake/platforms.cmake CMakeCache.txt CMakeFiles/3.22.1-g37088a8-dirty/CMakeASMCompiler.cmake CMakeFiles/3.22.1-g37088a8-dirty/CMakeCCompiler.cmake CMakeFiles/3.22.1-g37088a8-dirty/CMakeCXXCompiler.cmake CMakeFiles/3.22.1-g37088a8-dirty/CMakeSystem.cmake CMakeFiles/FindOpenMP/OpenMPCheckVersion.c CMakeFiles/FindOpenMP/OpenMPCheckVersion.cpp CMakeFiles/FindOpenMP/OpenMPTryFlag.c CMakeFiles/FindOpenMP/OpenMPTryFlag.cpp: phony


#############################################
# Clean all the built files.

build clean: CLEAN


#############################################
# Print all primary targets available.

build help: HELP


#############################################
# Make the all target the default.

default all
